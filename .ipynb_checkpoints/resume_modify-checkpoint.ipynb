{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6539ee-77cc-4296-8240-6a78a6f6d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 12:26:08.490 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:08.744 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\AICTIE_Microsoft_Project\\Environment\\project_1\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-09 12:26:08.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:08.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.270 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.278 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.279 Session state does not function when running a script without `streamlit run`\n",
      "2025-03-09 12:26:11.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-09 12:26:11.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pdfplumber\n",
    "import json\n",
    "import spacy\n",
    "import google.generativeai as genai\n",
    "from docx import Document\n",
    "from fpdf import FPDF\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyCCYQlEZYJ1CHp5Xj4XNtR8BVjP5S2m1-Q\"\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    st.error(\"⚠ Gemini API key not found. Please set it in your .env file.\")\n",
    "    st.stop()\n",
    "\n",
    "# Configure Gemini AI\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Load spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(file):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(file) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                extracted_text = page.extract_text()\n",
    "                if extracted_text:\n",
    "                    text += extracted_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Extract text from DOCX\n",
    "def extract_text_from_docx(file):\n",
    "    try:\n",
    "        doc = Document(file)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs]).strip()\n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Error extracting text from DOCX: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Parse resume file\n",
    "def parse_resume(file):\n",
    "    if file.name.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(file), \"pdf\"\n",
    "    elif file.name.endswith(\".docx\"):\n",
    "        return extract_text_from_docx(file), \"docx\"\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Extract sections from resume\n",
    "def extract_sections(resume_text):\n",
    "    sections = {}\n",
    "    current_section = \"Other\"\n",
    "    lines = resume_text.split(\"\\n\")\n",
    "    section_titles = [\"Technical Skills\", \"Soft Skills\", \"Certifications\", \"Experience\", \"Education\", \"Projects\"]\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if any(title.lower() in line.lower() for title in section_titles):\n",
    "            current_section = line.strip()\n",
    "            sections[current_section] = []\n",
    "        else:\n",
    "            sections.setdefault(current_section, []).append(line)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# Extract skills using Gemini AI\n",
    "def extract_skills_gemini(job_desc):\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    prompt = f\"\"\"\n",
    "    Extract key skills, tools, technologies, and relevant qualifications from this job description.\n",
    "    Classify them into categories like 'Technical Skills', 'Soft Skills', 'Certifications', 'Experience', 'Projects'.\n",
    "    Return the output as a JSON object where keys are section names and values are lists of skills.\n",
    "\n",
    "    Job Description:\n",
    "    {job_desc}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        extracted_data = json.loads(response.text)  # Ensure response is valid JSON\n",
    "        return extracted_data\n",
    "    except json.JSONDecodeError:\n",
    "        st.error(\"⚠ Error: Failed to parse Gemini AI response.\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        st.error(f\"⚠ Gemini AI Error: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Ensure skills are not already present in the resume\n",
    "def filter_new_skills(extracted_data, resume_sections):\n",
    "    filtered_skills = {}\n",
    "\n",
    "    for section, skills in extracted_data.items():\n",
    "        existing_skills = set(\" \".join(resume_sections.get(section, [])).lower().split())\n",
    "        new_skills = [skill for skill in skills if skill.lower() not in existing_skills]\n",
    "\n",
    "        if new_skills:\n",
    "            filtered_skills[section] = new_skills\n",
    "    \n",
    "    return filtered_skills\n",
    "\n",
    "# Get user approval for adding new skills\n",
    "def get_user_approval(filtered_skills):\n",
    "    approved_skills = {}\n",
    "\n",
    "    for section, skills in filtered_skills.items():\n",
    "        approved = []\n",
    "        for skill in skills:\n",
    "            key = f\"{section}_{skill}\"\n",
    "            if key not in st.session_state:\n",
    "                st.session_state[key] = False\n",
    "\n",
    "            st.session_state[key] = st.checkbox(f\"Add to {section}: {skill}?\", value=st.session_state[key])\n",
    "\n",
    "            if st.session_state[key]:\n",
    "                approved.append(skill)\n",
    "\n",
    "        if approved:\n",
    "            approved_skills[section] = approved\n",
    "    \n",
    "    return approved_skills\n",
    "\n",
    "# Update resume without changing the format\n",
    "def update_resume(sections, approved_skills):\n",
    "    for section, skills in approved_skills.items():\n",
    "        if section in sections:\n",
    "            sections[section].append(\", \".join(skills))\n",
    "        else:\n",
    "            sections[section] = [\", \".join(skills)]\n",
    "    return sections\n",
    "\n",
    "# Convert updated sections to DOCX\n",
    "def save_as_docx(sections, original_docx):\n",
    "    doc = Document(original_docx)\n",
    "\n",
    "    for section, content in sections.items():\n",
    "        found = False\n",
    "        for para in doc.paragraphs:\n",
    "            if para.text.strip() == section:\n",
    "                found = True\n",
    "                para.add_run(\"\\n\" + \"\\n\".join(content))\n",
    "                break\n",
    "        \n",
    "        if not found:  # Add new section if missing\n",
    "            doc.add_paragraph(section, style=\"Heading 1\")\n",
    "            doc.add_paragraph(\"\\n\".join(content))\n",
    "\n",
    "    output_path = \"Updated_Resume.docx\"\n",
    "    doc.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "# Convert updated sections to PDF\n",
    "def save_as_pdf(sections):\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    for section, content in sections.items():\n",
    "        pdf.set_font(\"Arial\", style='B', size=14)\n",
    "        pdf.cell(200, 10, txt=section.encode(\"utf-8\", \"ignore\").decode(\"utf-8\"), ln=True, align='L')\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "        pdf.ln(5)\n",
    "        \n",
    "        for line in content:\n",
    "            clean_text = line.encode(\"utf-8\", \"ignore\").decode(\"utf-8\")\n",
    "            pdf.multi_cell(0, 10, txt=clean_text)\n",
    "        pdf.ln(5)\n",
    "\n",
    "    output_path = \"Updated_Resume.pdf\"\n",
    "    pdf.output(output_path, \"F\")\n",
    "    return output_path\n",
    "\n",
    "# Improve ATS score calculation\n",
    "def calculate_ats_score(text1, text2):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\").fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity([vectors[0]], [vectors[1]])[0][0] * 100\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"🔍 AI-Powered Resume Enhancer with ATS Scoring (Gemini AI)\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"📂 Upload your resume\", type=[\"pdf\", \"docx\"])\n",
    "job_description = st.text_area(\"📝 Paste the job description here\")\n",
    "\n",
    "if uploaded_file and job_description:\n",
    "    resume_text, file_type = parse_resume(uploaded_file)\n",
    "\n",
    "    if resume_text:\n",
    "        sections = extract_sections(resume_text)\n",
    "        extracted_data = extract_skills_gemini(job_description)\n",
    "\n",
    "        if extracted_data:\n",
    "            filtered_skills = filter_new_skills(extracted_data, sections)\n",
    "            st.subheader(\"✅ Select new skills to add:\")\n",
    "            approved_skills = get_user_approval(filtered_skills)\n",
    "\n",
    "            updated_sections = update_resume(sections, approved_skills)\n",
    "            ats_score_old = calculate_ats_score(job_description, resume_text)\n",
    "            updated_resume_text = \"\\n\".join([f\"{sec}:\\n\" + \"\\n\".join(content) for sec, content in updated_sections.items()])\n",
    "            ats_score_new = calculate_ats_score(job_description, updated_resume_text)\n",
    "\n",
    "            st.write(f\"### 📊 ATS Score (Old Resume): {ats_score_old:.2f}%\")\n",
    "            st.write(f\"### 📊 ATS Score (New Resume): {ats_score_new:.2f}%\")\n",
    "\n",
    "            output_file = save_as_docx(updated_sections, uploaded_file) if file_type == \"docx\" else save_as_pdf(updated_sections)\n",
    "            with open(output_file, \"rb\") as f:\n",
    "                st.download_button(\"📥 Download Updated Resume\", f, file_name=output_file)\n",
    "    else:\n",
    "        st.error(\"❌ Unable to extract text from the resume. Please check the file format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76c9fb-51ff-4da5-b348-4af7d87815f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
